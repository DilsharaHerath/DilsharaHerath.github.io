---
title: "FlowSegModel: Weather-Resilient Semantic Segmentation"
status: "Research Publication"
hero: "/images/projects/FlowSeg/architecture.png"
primary_link_text: "Paper"
primary_link_url: "https://drive.google.com/file/d/19cxAAo216SmKzexCfNDDKUzaRORCupHO/view?usp=drive_link"
# secondary_link_text: "ArXiv"  # Add if preprint available
# secondary_link_url: ""
Keywords: "Semantic Segmentation, Optical Flow, Adverse Weather, DeepLabV3, RAFT, SEA-RAFT, Autonomous Driving"
excerpt: >
  Fuses RGB and SEA-RAFT optical flow into 5-channel DeepLabV3+ for robust segmentation on VKITTI2, achieving 0.8034 mIoU in fog/rain (4.4% degradation).
order: 12
---

## Project Overview

Developed FlowSegModel, a modified DeepLabV3+ (ResNet-101) fusing 3-channel RGB with 2-channel optical flow (from fine-tuned SEA-RAFT) for semantic segmentation under adverse weather (fog, rain, overcast). On VKITTI2 dataset, attains mIoU of 0.8406 (normal) and 0.8034 (adverse)—minimal 4.4% drop—via motion cues compensating visibility loss. SEA-RAFT optical flow outperforms RAFT/classical methods (Farneback/Horn-Schunck) by 96%+ EPE reduction; ablation shows RGB+flow 46.1% mIoU gain over flow-only.

### Key Components and Methodology

1. **Dataset Preparation**  
   VKITTI2 synthetic benchmark: RGB pairs, flow GT, segmentation labels across weather (clone/normal, fog, rain, overcast, etc.) and views (15°/30° left/right). Flow denormalized: \( f = \frac{2}{2^{16}-1} \cdot \text{bgr}_{RG} - 1 \), scaled to pixels; 5-channel concat (RGB+flow u/v); resize 384×1248.

2. **Optical Flow Estimation**  
   Fine-tuned RAFT/SEA-RAFT (pretrained + VKITTI2); classical Farneback/Horn-Schunck direct eval. Metrics: EPE \( \sqrt{(u - u_{gt})^2 + (v - v_{gt})^2} \); F1-all outliers (EPE>3 & relative>0.05).

3. **Segmentation Architecture (FlowSegModel)**  
   DeepLabV3+ encoder-decoder: First conv 3→5 channels; ASPP with tuned dilations; DeepLabHead (2048→7 classes). Train: AdamW (1e-4 LR), CE loss, 20 epochs early-stop (mIoU val), batch=16.

4. **Evaluation Metrics**  
   mIoU \( \frac{1}{C} \sum_c \frac{TP_c}{TP_c + FP_c + FN_c} \); macro Precision/Recall/F1. SEA-RAFT MoL loss: \( L_{MoL} = -\frac{1}{2HW} \sum \log[\text{MixLap}] \).

## Technical Contributions

- Customized DeepLabV3+ for 5-channel RGB+flow input, resilient to weather via motion fusion.  
- Fine-tuned SEA-RAFT/RAFT: EPE 0.78/1.79 (fine-tuned) vs. 512+ classical; SEA-RAFT 56.6% better than RAFT.  
- Weather-robust mIoU (0.80 adverse); ablation validates fusion (flow-only IoU drops 19-82%).  
- Advances AV perception; PyTorch impl on A100 GPUs.

## Visual Results

<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 1.5rem; margin: 2rem 0;">
  <figure>
    <img src="/images/projects/FlowSeg_MARC/Method.drawio.png" alt="FlowSegModel architecture overview" style="width: 100%; height: auto; min-height: 400px; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); object-fit: cover;">
    <figcaption>Architectural overview of the FlowSegModel</figcaption>
  </figure>
  <figure>
    <img src="/images/projects/FlowSeg_MARC/deeplab.png" alt="DeepLabV3+ encoder-decoder" style="width: 100%; height: auto; min-height: 400px; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); object-fit: cover;">
    <figcaption>Encoder-Decoder architecture of DeepLabV3+, the semantic segmentation framework used in our FlowSegModel</figcaption>
  </figure>
</div>

<div class="project-gallery" style="display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 1.5rem; margin: 2rem 0;">
  <figure>
    <img src="/images/projects/FlowSeg_MARC/flow1.png" alt="Optical flow under weather variants" style="width: 100%; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
    <figcaption>Optical flow visualization for a single scene under varying weather conditions</figcaption>
  </figure>
  <figure>
    <img src="/images/projects/FlowSeg_MARC/Segmentation_Results.jpg" alt="Segmentation predictions" style="width: 100%; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
    <figcaption>RGB/GT vs. predicted masks across weather</figcaption>
  </figure>
</div>

### Optical Flow Comparison (Full Width Table)
| Model       | Condition  | EPE     | F1-all | px<1   | px<3   | px<5    |
|-------------|------------|---------|--------|--------|--------|--------|
| **SEA-RAFT** | Pre-trained | 13.1929 | 60.18% | 30.02% | 65.42% | 76.81% |
|             | Fine-tuned  | **0.7758** | **3.67%** | **89.73%** | **95.48%** | **98.78%** |
| **RAFT**     | Pre-trained | 19.6173 | 76.59% | 13.14% | 23.41% | 31.83% |
|             | Fine-tuned  | 1.7861  | 10.67% | 67.58% | 88.92% | 94.02% |
| Farneback  | N/A        | 512.1124| 100%   | 0%     | 0%     | 0%     |
| Horn-Schunck| N/A       | 512.4921| 100%   | 0%     | 0%     | 0%     |

### Segmentation Metrics by Class (Full Width Table)
| Class      | Normal IoU | Normal F1 | Adverse IoU | Adverse F1  |
|------------|------------|-----------|--------------|----------------------|
| Background| 0.9099    | 0.9528   | 0.8731      | 0.9323              |
| Vehicle   | 0.8011    | 0.8896   | **0.8375**  | 0.9116              |
| Road      | 0.8109    | 0.8956   | 0.6996      | 0.8232              |
| **mIoU**  | **0.8406**| -        | **0.8034**  | -                   |

### Ablation: Flow-Only vs. Full Model (Adverse)
| Class      | Flow-Only IoU | Full Model IoU | Gain  |
|------------|---------------|----------------|---------------|
| Background| 0.7115       | 0.8731        | +19.7%       |
| Vehicle   | 0.1431       | 0.8375        | +82.3%       |
| Road      | 0.4753       | 0.6996        | +36.3%       |

## Acknowledgments

Conducted at Multidisciplinary AI Research Centre (MARC), University of Peradeniya, under Prof. Roshan Godaliyadda and Prof. Parakrama Ekanayake.
